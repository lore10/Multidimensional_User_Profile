{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "#from stop_words import get_stop_words\n",
    "import nltk\n",
    "from string import punctuation \n",
    "from nltk.corpus import stopwords\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "stop_words = [unidecode(stopW) for stopW in stopwords.words('spanish')]\n",
    "non_words = list(punctuation)\n",
    "non_words.extend(['¿', '¡', 'q', 'd', 'x', 'xq', '...', '..'])\n",
    "stop_words = stop_words + non_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from writereadfile import *\n",
    "import word2vec\n",
    "from em_utilities_LORE3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model300 = word2vec.load('tweetsNOStemmed_words2vec300.bin')\n",
    "vocabulary=list(model300.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "politicians=['CynthiaViteri6',\n",
    "'LassoGuillermo',\n",
    "'pesanteztwof',\n",
    "'daloes10',\n",
    "'IvanEspinelM',\n",
    "'Lenin',\n",
    "'PacoMoncayo',\n",
    "'ZuquilandaDuque',\n",
    "'a_alcivar','andrespaezec','JorgeGlas','MauricioPozoEC','MonseBustamant','ramiroaguilart',\n",
    "'CristinaReyesec','fcorderoc','HenryKronfle','irinacabezas','marcelaguinaga','mmcuesta',\n",
    "'MoisesTacle','PaolaVintimilla','RamiroGonzalezJ','lcparodi', \n",
    "'AlbertoAcostaE','AbAlvaroNoboa', 'jaimenebotsaadi',\n",
    "'LourdesTiban', 'PaulCarrascoC', 'MashiRafael', 'natasha_rojas',\n",
    "'jaimenebotsaadi','MauricioRodasEC','PoliticoRadical','VeroGallardoEC','mckronfle','AndresCarrion2',\n",
    "'lenhurtado',\n",
    "'martharoldos',\n",
    "'Presidencia_Ec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_candidates=load_json('all_tweets_politicans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the tweets of the users in the file 1 with EM, consider 7 clusters and print the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_tweets=load_json('citizensPlus_politiciansTest/users_tweetsChosen1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63104\n"
     ]
    }
   ],
   "source": [
    "documents_vectors=load_json('citizensPlus_politiciansTest/tweetsChosen_vecs1')\n",
    "print(len(documents_vectors))\n",
    "\n",
    "#Initializing cluster means\n",
    "data_centroids300=load_json('model300/data_centroids300')\n",
    "means=data_centroids300['centroids']['7']\n",
    "\n",
    "clusters_for_tweets=assign_clusters(documents_vectors, means)  #take the vectors that are not normalized\n",
    "num_clusters=7\n",
    "num_docs = np.array(documents_vectors).shape[0]\n",
    "documents_vectors = normalize(documents_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63104 300 7\n",
      "1000 300 7\n"
     ]
    }
   ],
   "source": [
    "#Initializing cluster weights\n",
    "weights = []\n",
    "for i in range(num_clusters):\n",
    "    # Compute the number of data points assigned to cluster i:\n",
    "    num_assigned = np.count_nonzero(clusters_for_tweets == i)# YOUR CODE HERE\n",
    "    w = float(num_assigned) / num_docs\n",
    "    weights.append(w)\n",
    "\n",
    "###Initializing covariances\n",
    "covs = []\n",
    "for i in range(num_clusters):\n",
    "    member_rows = documents_vectors[clusters_for_tweets==i]\n",
    "    cov = ((((member_rows*member_rows)-2*(member_rows.dot(np.diag(means[i])))).sum(axis=0))/member_rows.shape[0])+(np.array(means[i])*np.array(means[i]))\n",
    "    cov[cov < 1e-8] = 1e-8\n",
    "    covs.append(cov)\n",
    "    \n",
    "classification = EM_for_high_dimension(documents_vectors, means, covs, weights, cov_smoothing=1e-10)\n",
    "## classification = {'weights':weights,'means':mu,'covs':Sigma,'loglik':ll_trace,'resp':resp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43762815.269406162, 44904932.692161798, 44761719.986305594]\n",
      "[ 0.22515379  0.04414745  0.15733301  0.08516643  0.02673618  0.12732086\n",
      "  0.33414227]\n"
     ]
    }
   ],
   "source": [
    "print(classification['loglik'])  ##7 clusters\n",
    "print(classification['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_json('citizensPlus_politiciansTest/responsibility_7Clus_1', classification['resp'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_tweetsChosenPol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63104"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classification['resp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CynthiaViteri6 [  1.6   3.   37.2   0.7   2.5  26.5  28.5]\n",
      "LassoGuillermo [  0.7  21.6  45.3   0.3   1.1  25.9   5.2]\n",
      "pesanteztwof [  0.4   8.8  47.4   1.6   0.6  35.4   5.8]\n",
      "daloes10 [  5.9   7.5  57.5   0.1   0.7  15.   13.3]\n",
      "IvanEspinelM [  3.2   8.2  49.8   0.    2.3  29.8   6.8]\n",
      "Lenin [  0.    3.3  42.5   0.    0.8  34.8  18.5]\n",
      "PacoMoncayo [  1.    9.5  30.9   4.3   0.9  46.5   7.1]\n",
      "ZuquilandaDuque [  0.6   4.6  43.2   0.    1.1  42.7   7.9]\n",
      "a_alcivar [  0.8   1.   25.2   0.9   0.8  55.4  15.9]\n",
      "andrespaezec [  1.6   3.9  43.7   5.2   1.1  21.8  22.7]\n"
     ]
    }
   ],
   "source": [
    "politicians_classification=classification['resp'][-12122:]\n",
    "pol=users_tweets[-10:]\n",
    "index=0\n",
    "multiProfile_users=[]\n",
    "for u in pol:\n",
    "    responsibilities=[]\n",
    "    for t in u['tweets_chosen']:\n",
    "        responsibilities.append(politicians_classification[index])\n",
    "        index+=1\n",
    "        #print(t[1])\n",
    "        #print(np.argmax(classification['resp'][index]))\n",
    "    #print(len(responsibilities))\n",
    "    sum_responsibilities=(np.array(responsibilities).sum(axis=0))\n",
    "    #print(sum_responsibilities)\n",
    "    #print(type(sum_responsibilities))\n",
    "    multidim_profile=np.around(sum_responsibilities/sum_responsibilities.sum(), decimals=3)*100\n",
    "    print(u['user'],multidim_profile)\n",
    "    #multiProfile_users.append((u,multidim_profile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RUN THE TEST FOR 22 CLUSTERS IN THE 4 FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "22\n",
      "63104 300 22\n",
      "1000 300 7\n",
      "[46055400.632713318, 46963690.302444138, 46876439.554090865]\n",
      "[ 0.01272824  0.12381111  0.02575967  0.04459186  0.00326946  0.03684904\n",
      "  0.00086216  0.05262751  0.02472171  0.02163325  0.02668815  0.00327493\n",
      "  0.05492082  0.02107256  0.0740434   0.03381363  0.02049235  0.01324648\n",
      "  0.0845549   0.01686915  0.24614491  0.05802471]\n",
      "CynthiaViteri6 [  0.1   9.6   0.5   7.2   0.1   0.1   0.   26.9   1.5   0.1   3.5   0.\n",
      "   0.6   0.8  14.2   5.    0.3   1.3   3.3  21.5   3.    0.4]\n",
      "LassoGuillermo [  0.1   6.7   1.2   3.5   0.    0.1   0.    6.8   1.3   0.1  21.9   0.\n",
      "   0.4   2.9  36.7  12.4   0.2   3.2   1.1   0.8   0.5   0. ]\n",
      "pesanteztwof [  0.4   7.9   0.9   3.6   0.    0.    0.    8.3   1.8   0.4  10.8   0.\n",
      "   0.    8.   38.6  12.2   0.1   3.9   0.4   2.5   0.    0. ]\n",
      "daloes10 [  0.1  12.9   1.9   3.    0.    0.3   0.   11.5   0.3   0.4   7.2   0.\n",
      "   2.    2.4  33.5   6.3   1.    6.8   2.1   0.1   8.2   0. ]\n",
      "IvanEspinelM [  0.   10.8   3.    2.2   0.    0.    0.    2.3   2.4   0.    6.9   0.\n",
      "   1.6   5.3  45.    8.3   2.3   7.1   0.5   0.    2.1   0. ]\n",
      "Lenin [  0.   15.5   1.7   6.9   0.    0.    0.    1.6   5.9   0.    3.9   0.\n",
      "   0.8   2.5  34.5   9.6   0.    9.4   5.8   0.    1.9   0. ]\n",
      "PacoMoncayo [  0.4   5.    0.5   5.4   0.    0.    0.1   6.    1.6   3.9  12.6   0.\n",
      "   0.5   5.7  27.8  25.2   0.1   1.4   1.8   0.6   1.3   0.1]\n",
      "ZuquilandaDuque [  0.    6.8   1.1  12.6   0.    0.    0.    6.2   1.7   0.    5.6   0.\n",
      "   0.    0.6  45.6  14.1   0.    2.9   1.6   0.1   1.1   0. ]\n",
      "a_alcivar [  0.2  12.5   0.8  29.6   0.    0.1   0.1   5.6   5.9   0.    0.8   0.\n",
      "   0.4   0.8  35.    2.1   0.2   0.5   2.8   0.5   1.2   0.8]\n",
      "andrespaezec [  0.4  12.9   0.9   8.8   0.1   0.    0.   30.9   0.8   4.7   2.6   0.\n",
      "   1.    3.6  16.2   6.5   0.7   1.7   2.6   1.9   3.4   0.2]\n",
      "2\n",
      "22\n",
      "74188 300 22\n",
      "1000 300 7\n",
      "[54472779.609029755, 55680196.367612347, 55621939.533275999]\n",
      "[ 0.01476921  0.06780986  0.01653531  0.04349413  0.01209502  0.04183679\n",
      "  0.00182976  0.04655551  0.07524115  0.02729951  0.00639531  0.00247171\n",
      "  0.05646012  0.024843    0.05644078  0.03438109  0.02009976  0.02207942\n",
      "  0.08970231  0.01669548  0.24988114  0.07308364]\n",
      "JorgeGlas [  0.4   5.2   0.8  12.2   0.2   0.1   0.    4.2  14.8   0.    0.6   0.\n",
      "   0.4   6.9  20.2  13.1   0.9  12.4   4.3   2.2   1.    0. ]\n",
      "MauricioPozoEC [  0.5   2.1   0.    3.1   1.    0.    0.    8.3   2.4   0.    7.8   0.\n",
      "   0.5   2.3  33.6  26.6   0.    7.7   2.3   1.    0.8   0. ]\n",
      "MonseBustamant [  0.   11.8   1.7   6.5   0.    0.1   0.    3.9   2.3   0.    3.9   0.\n",
      "   0.6   1.1  32.4  21.6   0.    7.3   0.6   2.9   3.5   0. ]\n",
      "ramiroaguilart [  0.8   6.3   2.3   4.7   0.3   0.8   0.1  18.7   0.6   0.1   1.5   0.\n",
      "   2.4   0.5   9.2   1.2   4.2   0.8   5.8   2.2  37.3   0.2]\n",
      "CristinaReyesec [  0.1   3.9   0.8  10.1   0.3   0.2   0.1  10.4   8.5   0.    3.    0.\n",
      "   0.3   1.4  42.3   9.5   0.5   2.6   1.9   1.8   2.5   0. ]\n",
      "fcorderoc [  0.2   5.    1.2  14.8   0.6   0.    0.1   7.6  14.2   3.9   0.5   0.\n",
      "   0.3   3.4  20.8  10.4   0.4   5.6   1.9   4.1   2.9   2.2]\n",
      "HenryKronfle [  0.   10.9   0.    3.7   0.    0.    0.   13.9   2.1   0.    1.2   0.\n",
      "   0.    1.2  52.3   7.3   0.    3.7   0.    0.    3.7   0. ]\n",
      "irinacabezas [  0.3   1.9   0.2   9.9   0.2   1.5   0.    2.5  12.1  10.4   0.5   0.\n",
      "   0.    1.3  14.6  29.7   1.5   7.    2.1   2.5   1.7   0.2]\n",
      "marcelaguinaga [  0.1   2.2   3.1   8.5   0.    0.    0.    3.4  14.4   0.    0.3   0.\n",
      "   0.2   1.4  31.2  26.    0.1   6.8   0.8   1.2   0.3   0.1]\n",
      "mmcuesta [  0.3   7.6   1.5   3.8   1.3   3.2   0.3   4.9   2.    0.7   2.8   0.\n",
      "   2.8   8.5   0.9   1.1   6.    4.1  22.6   2.6  17.5   5.5]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type 'ndarray' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ecdb22bc5312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mmultiProfile_users\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultidim_profile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0msave_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'citizensPlus_politiciansTest/multiprofile_politicians_ALLCLusters'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultiProfile_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/JupyterProjects/dgo_ImprovedThesis/writereadfile.py\u001b[0m in \u001b[0;36msave_json\u001b[0;34m(filename, data)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}.json'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'ndarray' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "num_tweetsChosenPol=[12122, 8916, 18918, 18577] ##the 399 users'tweets were divided in 4 files (90 normal users + 10 politicians)\n",
    "multiProfile_users=[]\n",
    "for j in range(0,2):\n",
    "    print(j+1)\n",
    "    users_tweets=load_json('citizensPlus_politiciansTest/users_tweetsChosen'+str(j+1))\n",
    "    pol=users_tweets[-10:]\n",
    "    documents_vectors=load_json('citizensPlus_politiciansTest/tweetsChosen_vecs'+str(j+1))\n",
    "    \n",
    "    data_centroids300=load_json('model300/data_centroids300') #load the centroids for 300dim: \n",
    "    #['3', '5', '6', '8', '10', '20', '30', '80', '7']\n",
    "    \n",
    "    for key in ['22']:  #data_centroids300['centroids']:\n",
    "        #Initializing cluster means\n",
    "        means=data_centroids300['centroids'][key]\n",
    "        clusters_for_tweets=assign_clusters(documents_vectors, means)  #take the vectors that are not normalized\n",
    "        num_clusters=len(means)\n",
    "        print(num_clusters)\n",
    "        num_docs = np.array(documents_vectors).shape[0]\n",
    "        documents_vectors = normalize(documents_vectors)\n",
    "        \n",
    "        #Initializing cluster weights\n",
    "        weights = []\n",
    "        for i in range(num_clusters):\n",
    "            # Compute the number of data points assigned to cluster i:\n",
    "            num_assigned = np.count_nonzero(clusters_for_tweets == i)# YOUR CODE HERE\n",
    "            w = float(num_assigned) / num_docs\n",
    "            weights.append(w)\n",
    "\n",
    "        ###Initializing covariances\n",
    "        covs = []\n",
    "        for i in range(num_clusters):\n",
    "            member_rows = documents_vectors[clusters_for_tweets==i]\n",
    "            cov = ((((member_rows*member_rows)-2*(member_rows.dot(np.diag(means[i])))).sum(axis=0))/member_rows.shape[0])+(np.array(means[i])*np.array(means[i]))\n",
    "            cov[cov < 1e-8] = 1e-8\n",
    "            covs.append(cov)\n",
    "    \n",
    "        classification = EM_for_high_dimension(documents_vectors, means, covs, weights, cov_smoothing=1e-10)\n",
    "        ## classification = {'weights':weights,'means':mu,'covs':Sigma,'loglik':ll_trace,'resp':resp}\n",
    "        \n",
    "        ## RESULTS\n",
    "        print(classification['loglik'])  ##7 clusters\n",
    "        print(classification['weights'])\n",
    "        \n",
    "        save_json('citizensPlus_politiciansTest/responsibility_'+str(num_clusters)+'Clus_'+str(j+1), classification['resp'].tolist())\n",
    "    \n",
    "        politicians_classification=classification['resp'][-num_tweetsChosenPol[j]:]\n",
    "        index=0\n",
    "        for u in pol:\n",
    "            responsibilities=[]\n",
    "            for t in u['tweets_chosen']:\n",
    "                responsibilities.append(politicians_classification[index])\n",
    "                index+=1\n",
    "                #print(t[1])\n",
    "                #print(np.argmax(classification['resp'][index]))\n",
    "            #print(len(responsibilities))\n",
    "            sum_responsibilities=(np.array(responsibilities).sum(axis=0))\n",
    "            #print(sum_responsibilities)\n",
    "            #print(type(sum_responsibilities))\n",
    "            multidim_profile=np.around(sum_responsibilities/sum_responsibilities.sum(), decimals=3)*100\n",
    "            print(u['user'],multidim_profile)\n",
    "            multiProfile_users.append((u,multidim_profile))\n",
    "    \n",
    "#save_json('citizensPlus_politiciansTest/multiprofile_politicians_ALLCLusters',multiProfile_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "22\n",
      "74240 300 22\n",
      "1000 300 7\n",
      "[54478903.389378667, 55837671.127430856, 55767384.27355621]\n",
      "[ 0.01575009  0.08397949  0.0374589   0.04648973  0.00128564  0.03537669\n",
      "  0.00283306  0.04124661  0.06734851  0.02181424  0.02185609  0.00257104\n",
      "  0.03723221  0.03071455  0.08447492  0.0297835   0.0177362   0.00968001\n",
      "  0.08641371  0.01331411  0.22528558  0.08735511]\n",
      "MoisesTacle [  0.    2.3   2.2   4.2   0.    0.    0.    3.5   5.7   0.   18.9   0.\n",
      "   0.    1.5  22.9  35.8   0.3   0.4   0.2   2.1   0.1   0. ]\n",
      "PaolaVintimilla [  0.8   5.3   9.7  15.    0.1   0.5   0.   14.6   7.2   0.    1.4   0.\n",
      "   1.6   1.2  11.5   3.1   0.7  14.5   5.8   1.8   5.1   0.3]\n",
      "RamiroGonzalezJ [  0.    8.5   1.6   5.4   0.    0.1   0.    4.3   5.5   0.1  12.9   0.\n",
      "   0.6   5.1  38.   12.1   0.5   3.2   0.9   0.5   0.7   0. ]\n",
      "lcparodi [  1.5   2.5   0.5   3.6   0.    0.2   0.    1.4   0.7   0.5   0.2   0.\n",
      "   0.3   0.9   1.5   0.1   0.3   0.1  10.2   0.    2.5  72.8]\n",
      "AlbertoAcostaE [  0.    6.    0.   27.5   0.    0.    0.   15.7   9.    0.    0.    0.\n",
      "   0.    0.7  28.1   1.6   0.    0.1   6.3   2.    1.7   1.3]\n",
      "AbAlvaroNoboa [  0.    9.4   0.   14.2   0.    0.    0.   28.7   0.    0.    4.8   0.\n",
      "   0.    9.5  10.3  10.2   0.    8.2   0.    4.8   0.    0. ]\n",
      "jaimenebotsaadi [  0.2  11.9   0.8   7.1   0.    0.    0.    7.4  17.6   0.    8.9   0.\n",
      "   1.4   3.2  32.9   3.2   0.6   0.8   1.4   0.6   2.    0. ]\n",
      "LourdesTiban [  0.2   7.7   1.1  10.9   0.1   0.7   0.   22.8   3.7   1.    3.4   0.2\n",
      "   0.5   4.2  13.    7.7   1.1   0.7   7.2   4.    9.8   0.1]\n",
      "PaulCarrascoC [  0.1   3.9   0.7   4.1   0.    0.    0.    1.7  28.2   0.    3.9   0.\n",
      "   0.6   3.8  36.6  11.6   0.3   1.    1.9   0.9   0.4   0. ]\n",
      "MashiRafael [  0.1  17.3   1.9  10.2   0.5   0.1   0.   14.    7.    0.1   0.8   0.\n",
      "   1.4   4.6  27.8   3.1   0.5   2.6   2.8   1.1   4.    0.2]\n",
      "4\n",
      "22\n",
      "83454 300 22\n",
      "1000 300 7\n",
      "[61003176.303782694, 62772103.842469163, 62812175.103111371, 62682866.47685995]\n",
      "[ 0.02038921  0.09189579  0.06146689  0.0507587   0.00339844  0.02005933\n",
      "  0.0019647   0.03740118  0.09830138  0.01405728  0.0194292   0.00180711\n",
      "  0.01966851  0.03408592  0.08810307  0.04194744  0.0144936   0.01741195\n",
      "  0.10218347  0.02547148  0.17161787  0.06408748]\n",
      "natasha_rojas [  0.4   7.3   0.2  15.2   0.    0.5   0.1   0.    9.7   0.2   2.1   0.\n",
      "   1.    1.2  39.2  10.1   0.7   3.8   3.4   2.6   1.8   0.4]\n",
      "jaimenebotsaadi [  0.6  15.8   0.4   8.2   0.    0.    0.    0.   15.4   0.    8.5   0.\n",
      "   0.8   2.5  36.9   4.9   0.3   1.8   1.7   0.9   1.2   0. ]\n",
      "MauricioRodasEC [  0.4   2.1   0.7   8.1   0.    0.    0.    0.   51.1   0.    3.8   0.\n",
      "   0.    3.5  13.1  12.6   0.1   1.2   2.3   0.6   0.3   0.3]\n",
      "PoliticoRadical [  1.1  23.6   0.1  11.1   0.4   0.9   0.    0.    1.6   0.    0.2   0.3\n",
      "   0.8   0.1  39.1   2.    0.2   6.5   5.2   0.5   6.3   0.1]\n",
      "VeroGallardoEC [  0.3   4.    0.    8.8   0.    0.    0.    0.   26.2   0.    0.9   0.\n",
      "   0.1   1.7  27.2  23.2   0.5   4.9   1.    0.9   0.2   0. ]\n",
      "mckronfle [  0.2  34.1   0.5   6.7   0.4   0.3   0.    0.    3.    0.2   1.1   0.\n",
      "   0.5   0.8  27.3   2.9   1.    1.6   4.2   0.4  14.7   0.1]\n",
      "AndresCarrion2 [  0.4   3.4   0.8  31.5   0.2   0.    4.8   0.    4.7   0.1   7.5   0.\n",
      "   0.3   1.3  10.5   9.3   0.6   1.5   5.5  13.2   3.    1.4]\n",
      "lenhurtado [  0.4  22.8   1.1  12.4   0.2   0.    0.4   0.    4.1   0.4   0.2   0.2\n",
      "   2.    0.7  32.    1.7   0.3   4.4   5.2   2.    8.7   0.8]\n",
      "martharoldos [  0.8  18.2   0.   15.6   0.    0.    0.    0.    4.4   1.    0.5   0.2\n",
      "   1.2   0.8  30.9   0.7   0.    0.8   7.9   3.3   8.4   5.3]\n",
      "Presidencia_Ec [  0.1   1.6   0.6  12.5   0.    0.    0.    0.    7.4   0.6   0.2   0.\n",
      "   0.    1.6  26.4  44.3   0.    3.    1.    0.5   0.1   0. ]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type 'ndarray' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bcd9e2e5c1d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mmultiProfile_users\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultidim_profile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0msave_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'citizensPlus_politiciansTest/multiprofile_politicians_ALLCLusters'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultiProfile_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/AleLore/JupyterProjects/dgo_ImprovedThesis/writereadfile.py\u001b[0m in \u001b[0;36msave_json\u001b[0;34m(filename, data)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}.json'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AleLore/anaconda/envs/py36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'ndarray' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "num_tweetsChosenPol=[12122, 8916, 18918, 18577]\n",
    "multiProfile_users=[]\n",
    "for j in range(2,4):\n",
    "    print(j+1)\n",
    "    users_tweets=load_json('citizensPlus_politiciansTest/users_tweetsChosen'+str(j+1))\n",
    "    pol=users_tweets[-10:]\n",
    "    documents_vectors=load_json('citizensPlus_politiciansTest/tweetsChosen_vecs'+str(j+1))\n",
    "    \n",
    "    data_centroids300=load_json('model300/data_centroids300') #load the centroids for 300dim: \n",
    "    #['3', '5', '6', '8', '10', '20', '30', '80', '7']\n",
    "    \n",
    "    for key in ['22']:  #data_centroids300['centroids']:\n",
    "        #Initializing cluster means\n",
    "        means=data_centroids300['centroids'][key]\n",
    "        clusters_for_tweets=assign_clusters(documents_vectors, means)  #take the vectors that are not normalized\n",
    "        num_clusters=len(means)\n",
    "        print(num_clusters)\n",
    "        num_docs = np.array(documents_vectors).shape[0]\n",
    "        documents_vectors = normalize(documents_vectors)\n",
    "        \n",
    "        #Initializing cluster weights\n",
    "        weights = []\n",
    "        for i in range(num_clusters):\n",
    "            # Compute the number of data points assigned to cluster i:\n",
    "            num_assigned = np.count_nonzero(clusters_for_tweets == i)# YOUR CODE HERE\n",
    "            w = float(num_assigned) / num_docs\n",
    "            weights.append(w)\n",
    "\n",
    "        ###Initializing covariances\n",
    "        covs = []\n",
    "        for i in range(num_clusters):\n",
    "            member_rows = documents_vectors[clusters_for_tweets==i]\n",
    "            cov = ((((member_rows*member_rows)-2*(member_rows.dot(np.diag(means[i])))).sum(axis=0))/member_rows.shape[0])+(np.array(means[i])*np.array(means[i]))\n",
    "            cov[cov < 1e-8] = 1e-8\n",
    "            covs.append(cov)\n",
    "    \n",
    "        classification = EM_for_high_dimension(documents_vectors, means, covs, weights, cov_smoothing=1e-10)\n",
    "        ## classification = {'weights':weights,'means':mu,'covs':Sigma,'loglik':ll_trace,'resp':resp}\n",
    "        \n",
    "        ## RESULTS\n",
    "        print(classification['loglik'])  ##7 clusters\n",
    "        print(classification['weights'])\n",
    "        \n",
    "        save_json('citizensPlus_politiciansTest/responsibility_'+str(num_clusters)+'Clus_'+str(j+1), classification['resp'].tolist())\n",
    "    \n",
    "        politicians_classification=classification['resp'][-num_tweetsChosenPol[j]:]\n",
    "        index=0\n",
    "        for u in pol:\n",
    "            responsibilities=[]\n",
    "            for t in u['tweets_chosen']:\n",
    "                responsibilities.append(politicians_classification[index])\n",
    "                index+=1\n",
    "                #print(t[1])\n",
    "                #print(np.argmax(classification['resp'][index]))\n",
    "            #print(len(responsibilities))\n",
    "            sum_responsibilities=(np.array(responsibilities).sum(axis=0))\n",
    "            #print(sum_responsibilities)\n",
    "            #print(type(sum_responsibilities))\n",
    "            multidim_profile=np.around(sum_responsibilities/sum_responsibilities.sum(), decimals=3)*100\n",
    "            print(u['user'],multidim_profile)\n",
    "            multiProfile_users.append((u,multidim_profile))\n",
    "    \n",
    "#save_json('citizensPlus_politiciansTest/multiprofile_politicians_ALLCLusters',multiProfile_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
